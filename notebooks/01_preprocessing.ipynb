{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import & load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip cache purge\n",
    "\n",
    "%pip install mne\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import read_raw_edf\n",
    "from mne.io import concatenate_raws\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"FigureCanvasAgg is non-interactive, and thus cannot be shown\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"Channel locations not available.*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Protocol\n",
    "\n",
    "This data set consists of over 1500 one- and two-minute EEG recordings, obtained from ***109 volunteers***, as described below.\n",
    "\n",
    "Subjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). Each subject performed ***14 experimental runs***: two one-minute baseline runs (one with eyes open, one with eyes closed), and three two-minute runs of each of the four following tasks:\n",
    "\n",
    "- **TASK 1**: A target appears on either the left or the right side of the screen. The subject opens and closes the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "- **TASK 2**: A target appears on either the left or the right side of the screen. The subject imagines opening and closing the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "- **TASK 3**: A target appears on either the top or the bottom of the screen. The subject opens and closes either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "- **TASK 4**: A target appears on either the top or the bottom of the screen. The subject imagines opening and closing either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "\n",
    "### Description of data:\n",
    "\n",
    "The experimental runs were:\n",
    "\n",
    "- Baseline, eyes open\n",
    "- Baseline, eyes closed\n",
    "- Task 1 (open and close left or right fist)\n",
    "- Task 2 (imagine opening and closing left or right fist)\n",
    "- Task 3 (open and close both fists or both feet)\n",
    "- Task 4 (imagine opening and closing both fists or both feet)\n",
    "\n",
    "Each annotation includes one of three codes (T0, T1, or T2):\n",
    "\n",
    "- **T0** corresponds to rest\n",
    "- **T1** corresponds to onset of motion (real or imagined) of\n",
    "        the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "        both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "- **T2** corresponds to onset of motion (real or imagined) of\n",
    "        the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "        both feet (in runs 5, 6, 9, 10, 13, and 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Run       | Task                                |\n",
    "|-----------|-------------------------------------|\n",
    "| 1         | Baseline, eyes open                 |\n",
    "| 2         | Baseline, eyes closed               |\n",
    "| 3, 7, 11  | Motor execution: left vs right hand |\n",
    "| 4, 8, 12  | Motor imagery: left vs right hand   |\n",
    "| 5, 9, 13  | Motor execution: hands vs feet      |\n",
    "| 6, 10, 14 | Motor imagery: hands vs feet        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EEGs were recorded from 64 electrodes as per the international system (excluding electrodes Nz, F9, F10, FT9, FT10, A1, A2, TP9, TP10, P9, and P10)\n",
    "\n",
    "<img width=100% src=../images/EGG_64.png>\n",
    "\n",
    "<img width=100% src=../images/64_channel_sharbrough.png>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subjects, runs, data_dir=\"../data/files/\"):\n",
    "    \"\"\"\n",
    "    Load and preprocess EEG data for given subjects and runs.\n",
    "    \"\"\"\n",
    "    all_raws = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        print(f\"\\n=== Loading data from_volunteer {subject} ===\")\n",
    "        try:\n",
    "            # Download data to the specified directory\n",
    "            raw_fnames = mne.datasets.eegbci.load_data(subject, runs, path=data_dir)\n",
    "            raws = [mne.io.read_raw_edf(f, preload=True, verbose=True) for f in raw_fnames]  \n",
    "            raw = mne.concatenate_raws(raws)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Skipping subject {subject} due to an error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Set standard montage\n",
    "        try:\n",
    "            raw.set_montage(\"standard_1005\", on_missing=\"ignore\")\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Could not set montage for subject {subject}: {e}\")\n",
    "\n",
    "        # Extract events from annotations\n",
    "        try:\n",
    "            events, _ = mne.events_from_annotations(raw)\n",
    "            new_annot = mne.annotations_from_events(\n",
    "                events=events, \n",
    "                event_desc=new_labels_events, \n",
    "                sfreq=raw.info['sfreq'], \n",
    "                orig_time=raw.info['meas_date']\n",
    "                )\n",
    "            raw.set_annotations(new_annot)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Could not update event labels for subject {subject}: {e}\")\n",
    "\n",
    "        all_raws.append(raw)\n",
    "\n",
    "    if not all_raws:\n",
    "        raise ValueError(\"No valid EEG data loaded. Check subject and run IDs.\")\n",
    "\n",
    "    # Concatenate all subjects' data\n",
    "    return mne.concatenate_raws(all_raws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [1] # subjects to load (from 1 to 109 volunteers)\n",
    "\n",
    "runs = [3]  # experimental runs for each subject\n",
    "# runs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "raw_data = load_data(subjects, runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_edf_files(data_dir=\"../data/files/\"):\n",
    "    \"\"\"\n",
    "    Recursively summarize the contents of all .edf files in the given directory.\n",
    "    \"\"\"\n",
    "    edf_files = glob.glob(os.path.join(data_dir, \"**/*.edf\"), recursive=True)\n",
    "    \n",
    "    if not edf_files:\n",
    "        print(\"No EDF files found in the directory or subdirectories.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(edf_files)} EDF files in {data_dir}**:\\n\")\n",
    "    \n",
    "    for edf_file in edf_files:\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(edf_file, preload=False, verbose=False)\n",
    "            info = raw.info\n",
    "            \n",
    "            rel_path = os.path.relpath(edf_file, data_dir)  # Get relative path for better readability\n",
    "            \n",
    "            print(f\"File: {rel_path}\")\n",
    "            print(f\"  - Channels: {len(info['ch_names'])}\")\n",
    "            print(f\"  - Length: {len(raw)}\")\n",
    "            print(f\"  - Sampling Frequency: {info['sfreq']} Hz\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {edf_file}: {e}\")\n",
    "\n",
    "# Run the function\n",
    "summarize_edf_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data)\n",
    "print(raw_data.info)\n",
    "print(raw_data.annotations)\n",
    "print(raw_data.annotations.description)\n",
    "print(raw_data.annotations.onset)\n",
    "print(raw_data.info['ch_names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegbci.standardize(raw_data)  # Standardize channel names\n",
    "print(raw_data.info)\n",
    "print(raw_data.info['ch_names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "raw_data.set_montage(montage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Show events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the events\n",
    "events, event_id = mne.events_from_annotations(raw_data)\n",
    "print(event_id)\n",
    "print(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = {\n",
    "    'rest' if k == np.str_('T0') else \n",
    "    'hands' if k == np.str_('T1') else \n",
    "    'feets': v \n",
    "    for k, v in event_id.items()\n",
    "}\n",
    "print(event_id)\n",
    "print(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (14, 5)\n",
    "mne.viz.plot_events(events, sfreq=raw_data.info['sfreq'], \n",
    "                     first_samp=raw_data.first_samp, event_id=event_id)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only EEG channels for further analysis \n",
    "picks = mne.pick_types(raw_data.info, meg=True, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "print(picks.shape)\n",
    "print(picks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.plot(picks=picks);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Show PSD Power Spectral Density\n",
    "\n",
    "The Power Spectral Density (PSD) is a way to analyze the frequency content of a signal. It tells us how the power of a signal is distributed across different frequencies. \n",
    "\n",
    "The PSD describes how the power (or variance) of a signal is distributed over different frequency components.\n",
    "\n",
    "It is computed using the Fourier Transform, which decomposes a time-domain signal into its frequency components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd = raw_data.compute_psd(picks=picks)\n",
    "psd.plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply ICA Independent Component Analysis\n",
    "\n",
    "ICA (Independent Component Analysis) is a technique used to separate mixed signals into independent components. In EEG/MEG analysis, it is mainly used to remove artifacts such as eye blinks, eye movements, and muscle noise.\n",
    "\n",
    "ICA decomposes a signal into a set of statistically independent components, allowing us to identify and remove noise sources without affecting neural signals.\n",
    "\n",
    "ICA is useful for:\n",
    "- Removing eye blink artifacts (blinks)\n",
    "- Removing eye movement and muscle artifacts\n",
    "- Separating neural activity from external noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ICA with 25 components\n",
    "raw_data_ica = raw_data.copy()\n",
    "raw_data_ica_filtered = raw_data_ica.filter(1, 70, picks=picks)\n",
    "ica = ICA(n_components=25, random_state=42, method='fastica', max_iter=800)\n",
    "\n",
    "# Fit ICA to the data\n",
    "ica.fit(raw_data_ica_filtered, picks=picks)\n",
    "\n",
    "# Plot ICA components\n",
    "ica.plot_sources(raw_data_ica_filtered, picks=range(0, 25))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.apply(raw_data_ica_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ica_filtered.plot(picks=picks);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert MNE plot to an image\n",
    "def raw_plot_to_image(raw_data, picks):\n",
    "    buf = BytesIO()\n",
    "    fig = raw_data.plot(picks=picks, show=False)\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight', dpi=150)  # Reduce empty space\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return np.array(Image.open(buf))\n",
    "\n",
    "# Create figure with tight layout\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('Raw Data BEFORE ICA vs. AFTER ICA', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot BEFORE ICA\n",
    "img_before = raw_plot_to_image(raw_data, picks)\n",
    "axes[0].imshow(img_before)\n",
    "axes[0].set_title('raw_data BEFORE ICA', fontsize=12)\n",
    "axes[0].axis('off')  # Hide axes completely\n",
    "axes[0].spines[:].set_visible(False)  # Hide borders\n",
    "\n",
    "# Plot AFTER ICA\n",
    "img_after = raw_plot_to_image(raw_data_ica_filtered, picks)\n",
    "axes[1].imshow(img_after)\n",
    "axes[1].set_title('raw_data AFTER ICA', fontsize=12)\n",
    "axes[1].axis('off')  # Hide axes completely\n",
    "axes[1].spines[:].set_visible(False)\n",
    "\n",
    "# Use tight_layout to optimize spacing\n",
    "plt.tight_layout(pad=0.1, w_pad=0.1, h_pad=0.1)  # Reduce the space between subplots\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_ica_raw = raw_data_ica_filtered.compute_psd(picks=picks, fmax=80)\n",
    "psd_ica_raw.plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Notch filter\n",
    "\n",
    "A Notch Filter (also called a Band-stop filter) is used to remove specific unwanted frequencies from a signal, particularly when a narrow frequency band causes interference or noise. In signal processing, the \"notch\" refers to the removal of frequencies within a small range, leaving the other frequencies untouched.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "- Passband and Stopband:\n",
    "\n",
    "\t- The passband is the range of frequencies that the filter allows to pass through without attenuation.\n",
    "\t- The stopband is the range of frequencies that the filter suppresses.\n",
    "\t- A notch filter specifically targets and reduces a narrow band of frequencies (the notch), while passing frequencies outside of that band.\n",
    "\n",
    "- Frequency Range:\n",
    "\n",
    "\t- The notch filter is designed to attenuate a specific frequency (or a small range of frequencies) while allowing the other frequencies to pass through. This is particularly useful when dealing with known interference frequencies, such as the power line frequency (50 Hz or 60 Hz) that can appear in many electrical signals.\n",
    "\n",
    "**Applications of Notch Filters:** \n",
    "- Power line interference: In electrical signals, the 50 Hz or 60 Hz power line frequency is a common source of noise. The notch filter is used to remove this frequency without affecting the rest of the signal.\n",
    "- Electroencephalography (EEG): In EEG data, notch filters are commonly applied to remove noise caused by electrical equipment, such as power line interference.\n",
    "- Audio processing: It can also be used to remove hum or buzz noises caused by equipment, such as electrical hum from a microphone or speakers.\n",
    "- Communication systems: To filter out specific unwanted frequencies or interference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Notch filter\n",
    "# notch_freq = 60\n",
    "# raw_data.notch_filter(notch_freq, fir_design='firwin')\n",
    "# raw_data.compute_psd().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Band-pass filter keep only alpha and beta waves\n",
    "# low_cutoff = 8\n",
    "# high_cutoff = 30\n",
    "# raw_data.filter(low_cutoff, high_cutoff, fir_design='firwin')\n",
    "# raw_data.compute_psd().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data.compute_psd().plot()\n",
    "# raw_data.compute_psd().plot(average=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filtered.plot_psd(average=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_filtered.copy().get_data()\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "data_standardized = scaler.fit_transform(data.T).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance Matrix Computation\n",
    "covariance_matrix = np.cov(data_standardized)\n",
    "\n",
    "# Eigenvalue and Eigenvector Decomposition\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# avoidng complex domain parts of eigenvalues\n",
    "eigenvalues = np.real(eigenvalues)\n",
    "eigenvectors = np.real(eigenvectors)\n",
    "\n",
    "# Feature Vector Formation\n",
    "# Sort eigenvalues and their corresponding eigenvectors\n",
    "idx = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance Matrix Computation\n",
    "covariance_matrix = np.cov(data_standardized)\n",
    "\n",
    "# Eigenvalue and Eigenvector Decomposition\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# avoidng complex domain parts of eigenvalues\n",
    "eigenvalues = np.real(eigenvalues)\n",
    "eigenvectors = np.real(eigenvectors)\n",
    "\n",
    "# Feature Vector Formation\n",
    "# Sort eigenvalues and their corresponding eigenvectors\n",
    "idx = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative explained variance\n",
    "explained_variance_ratio = np.cumsum(eigenvalues) / np.sum(eigenvalues) * 100\n",
    "\n",
    "# Create a DataFrame with the number of components and cumulative variance\n",
    "df_explained_variance = pd.DataFrame({\n",
    "    'Number of Components': range(1, len(eigenvalues) + 1),\n",
    "    'Cumulative Explained Variance (%)': explained_variance_ratio\n",
    "})\n",
    "\n",
    "# Display the DataFrame 10 first rows\n",
    "print(f\"{df_explained_variance.head(10)}\\n\\n\")\n",
    "\n",
    "# Select the top k eigenvectors\n",
    "k = 10  # Number of principal components to keep\n",
    "eigenvectors_reduced = eigenvectors[:, :k]\n",
    "\n",
    "# Recast the Data\n",
    "data_pca = np.dot(eigenvectors_reduced.T, data_standardized)\n",
    "\n",
    "# Visualize the cumulative explained variance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, k + 1), explained_variance_ratio[:k], marker='o', linestyle='--', color='b')\n",
    "plt.title('Cumulative Explained Variance by PCA Components')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.ylabel('Cumulative Explained Variance (%)')\n",
    "plt.xticks(range(1, k + 1))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vortex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
