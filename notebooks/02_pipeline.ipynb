{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import & load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
      "\u001b[0mFiles removed: 0 (0 bytes)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: mne in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: decorator in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (3.1.5)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (3.9.4)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (2.0.2)\n",
      "Requirement already satisfied: packaging in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (24.2)\n",
      "Requirement already satisfied: pooch>=1.5 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (1.15.1)\n",
      "Requirement already satisfied: tqdm in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from pooch>=1.5->mne) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: scikit-learn in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /sgoinfre/students/dgerwig-/miniforge/envs/vortex_env/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip cache purge\n",
    "\n",
    "%pip install mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# from mne.preprocessing import ICA\n",
    "# from mne import Epochs, pick_types, events_from_annotations\n",
    "# from mne.channels import make_standard_montage\n",
    "# from mne.io import concatenate_raws, read_raw_edf\n",
    "# from mne.datasets import eegbci\n",
    "# from mne.decoding import CSP\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "# from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "# from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "# import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.33333333 0.33333333 0.         0.33333333 0.33333333]\n",
      "Mean CV score: 0.267 (+/- 0.267)\n",
      "\n",
      "Testing real-time prediction simulation:\n",
      "Processed 10/15 samples. Current accuracy: 1.000\n",
      "Processed 15/15 samples. Current accuracy: 1.000\n",
      "\n",
      "Final accuracy on simulation: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "models_dir = '../models'\n",
    "\n",
    "# 1. Create the pipeline with dimensionality reduction and classification\n",
    "def create_processing_pipeline(n_components=0.95):\n",
    "    pipeline = Pipeline([\n",
    "        ('dimension_reduction', PCA(n_components=n_components)),\n",
    "        ('classifier', SVC(kernel='rbf'))\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# 2. Load the preprocessed data\n",
    "X_train = np.load(os.path.join(models_dir, 'X_preprocessed.npy'))\n",
    "y_train = np.load(os.path.join(models_dir, 'y_labels.npy'))\n",
    "\n",
    "# 3. Create and train the pipeline\n",
    "pipeline = create_processing_pipeline()\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate using cross-validation\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean CV score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "\n",
    "# 5. Save the trained pipeline\n",
    "pipeline_info = {\n",
    "    'pipeline_params': {\n",
    "        'pca_n_components': float(pipeline.named_steps['dimension_reduction'].n_components_),\n",
    "        'n_components_selected': int(pipeline.named_steps['dimension_reduction'].n_components_),\n",
    "        'explained_variance_ratio': [float(x) for x in pipeline.named_steps['dimension_reduction'].explained_variance_ratio_],\n",
    "        'classifier_params': {k: str(v) if isinstance(v, (np.int64, np.float64)) else v \n",
    "                            for k, v in pipeline.named_steps['classifier'].get_params().items()}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save pipeline information to JSON\n",
    "with open(os.path.join(models_dir, 'pipeline_info.json'), 'w') as f:\n",
    "    json.dump(pipeline_info, f, indent=4)\n",
    "\n",
    "# Save the complete pipeline using pickle\n",
    "with open(os.path.join(models_dir, 'trained_pipeline.pkl'), 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "# 6. Simulate real-time prediction (playback)\n",
    "def simulate_real_time_prediction(pipeline, X, y, chunk_size=10):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for i in range(0, len(X), chunk_size):\n",
    "        # Get a chunk of data\n",
    "        X_chunk = X[i:i + chunk_size]\n",
    "        y_chunk = y[i:i + chunk_size]\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_chunk)\n",
    "        \n",
    "        predictions.extend(y_pred.tolist())  # Convert to list\n",
    "        true_labels.extend(y_chunk.tolist())  # Convert to list\n",
    "        \n",
    "        # Calculate current accuracy\n",
    "        current_acc = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "        print(f\"Processed {i+len(X_chunk)}/{len(X)} samples. Current accuracy: {current_acc:.3f}\")\n",
    "        \n",
    "        # Simulate real-time delay\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    return predictions, true_labels\n",
    "\n",
    "# Test the real-time simulation\n",
    "print(\"\\nTesting real-time prediction simulation:\")\n",
    "predictions, true_labels = simulate_real_time_prediction(pipeline, X_train[:100], y_train[:100])\n",
    "final_accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "print(f\"\\nFinal accuracy on simulation: {final_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions:\n",
      "Number of epochs: 15\n",
      "Number of channels: 64\n",
      "Time points: 801\n",
      "\n",
      "PCA Pipeline:\n",
      "Cross-validation scores: [0.33333333 0.33333333 0.         0.33333333 0.33333333]\n",
      "Mean CV score: 0.267 (+/- 0.267)\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 9.6 (2.2e-16 eps * 64 dim * 6.7e+14  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 9.4 (2.2e-16 eps * 64 dim * 6.6e+14  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 9.3 (2.2e-16 eps * 64 dim * 6.5e+14  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 8.3 (2.2e-16 eps * 64 dim * 5.8e+14  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 9.3 (2.2e-16 eps * 64 dim * 6.6e+14  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=2 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=3 covariance using EMPIRICAL\n",
      "Done.\n",
      "\n",
      "CSP Pipeline:\n",
      "Cross-validation scores: [0.33333333 0.33333333 0.66666667 0.66666667 0.66666667]\n",
      "Mean CV score: 0.533 (+/- 0.327)\n"
     ]
    }
   ],
   "source": [
    "from mne.decoding import CSP\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import json\n",
    "\n",
    "# Load preprocessing info to get the channel information\n",
    "with open(os.path.join(models_dir, 'preprocessing_info.json'), 'r') as f:\n",
    "    preprocess_info = json.load(f)\n",
    "\n",
    "# Get dimensions\n",
    "n_epochs = len(X_train)\n",
    "n_channels = len(preprocess_info['channels'])\n",
    "n_times = X_train.shape[1] // n_channels\n",
    "\n",
    "print(f\"Data dimensions:\")\n",
    "print(f\"Number of epochs: {n_epochs}\")\n",
    "print(f\"Number of channels: {n_channels}\")\n",
    "print(f\"Time points: {n_times}\")\n",
    "\n",
    "# Reshape to (n_epochs, n_channels, n_times)\n",
    "X_train_3d = X_train.reshape(n_epochs, n_channels, n_times)\n",
    "\n",
    "def create_csp_pipeline(n_components=4):\n",
    "    pipeline = Pipeline([\n",
    "        ('csp', CSP(n_components=n_components, reg=None, log=True)),\n",
    "        ('classifier', SVC(kernel='rbf'))\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "def create_pca_pipeline(n_components=0.95):\n",
    "    pipeline = Pipeline([\n",
    "        ('dimension_reduction', PCA(n_components=n_components)),\n",
    "        ('classifier', SVC(kernel='rbf'))\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# Create pipelines\n",
    "pipelines = {\n",
    "    'PCA': create_pca_pipeline(),\n",
    "    'CSP': create_csp_pipeline()\n",
    "}\n",
    "\n",
    "# Evaluate each pipeline\n",
    "for name, pipe in pipelines.items():\n",
    "    if name == 'CSP':\n",
    "        # Use 3D data for CSP\n",
    "        scores = cross_val_score(pipe, X_train_3d, y_train, cv=5)\n",
    "    else:\n",
    "        # Use flattened data for PCA\n",
    "        scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    \n",
    "    print(f\"\\n{name} Pipeline:\")\n",
    "    print(f\"Cross-validation scores: {scores}\")\n",
    "    print(f\"Mean CV score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vortex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
